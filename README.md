# RAG PDF/Web QA - Multimodal Document Intelligence

Production-ready Retrieval-Augmented Generation system for answering questions based on uploaded PDFs (text + images) and web search. Built with modern AI and web technologies.

## Key Features

- ðŸ“„ **PDF Ingestion**: Extract text and images from PDFs using PyMuPDF
- ðŸ–¼ï¸ **Multimodal Vision**: GPT-4o Vision analyzes images (logos, charts, diagrams)
- ðŸ” **Semantic Search**: PostgreSQL + pgvector for efficient vector similarity search
- ðŸŒ **Web Search Integration**: Hybrid RAG with document + web sources
- âš¡ **Streaming Responses**: Real-time SSE streaming for instant feedback
- ðŸŽ¨ **Modern UI**: React + TypeScript + TailwindCSS + Framer Motion
- ðŸ³ **Docker Ready**: Full containerization with Docker Compose

---

## Authors and Purpose

This project is a collaboration for studying modern development and Artificial Intelligence technologies, developed by:

- **Larissa Rodrigues** (AI Engineer) - [LinkedIn](https://www.linkedin.com/in/lari-rodriggs/)
- **Vinicius de Moura** (Fullstack Software Engineer) - [LinkedIn](https://www.linkedin.com/in/deviniciusg/)
- **Sofia Rigonati** (Fullstack Software Engineer) - [LinkedIn](https://www.linkedin.com/in/sofia-rigonati-magalh%C3%A3es-louzada-7405b7250/)

---

## Architecture

```mermaid
flowchart TB
%% ---------- NODES ----------
User([ðŸ‘¤ User])

subgraph Frontend["ðŸ§­ Frontend (React + Vite)"]
    UI[UI Components]
    Renderer[Message Renderer]
    APIClient[API Client Â· SSE]
    UI --> Renderer
    UI --> APIClient
end

subgraph Backend["âš™ï¸ Backend (FastAPI)"]
    APIRoutes[API Routes] --> Orchestrator[Orchestrator]
    Orchestrator --> Route{Docs or Web?}

    subgraph DocsPipe["ðŸ“„ Document Pipeline"]
        Ingestion[PDF Ingestion]
        TextEx[Text Extractor]
        ImgEx[Image Extractor]
        Vector[Vector Search]
        Rerank[Semantic Reranking]

        Ingestion --> TextEx
        Ingestion --> ImgEx
        TextEx --> Vector
        Vector --> Rerank
    end

    subgraph WebPipe["ðŸŒ Web Retrieval"]
        WebSearch[Web Search API]
    end

    Route -->|Docs| Vector
    Route -->|Web| WebSearch

    Rerank --> Synth[Answer Synthesis]
    WebSearch --> Synth
    Synth --> GPT4o[GPT-4o Vision (Multimodal)]
    GPT4o --> Stream[Streamed Response]
end

subgraph Storage["ðŸ—„ï¸ Storage"]
    DB[(PostgreSQL + pgvector)]
    Media[(Media Files)]
end

Embeds[OpenAI Embeddings API]

%% ---------- CONNECTIONS ----------
User -->|Upload PDF / Ask Question| Frontend
Frontend -->|HTTP + SSE| Backend

Backend -->|Store pages & embeddings| DB
Backend -->|Save images| Media
Backend -->|Embed text| Embeds

Stream -->|SSE| Frontend
ImgEx -->|Save JPG| Media
TextEx -->|Store pages| DB
Vector -->|Similarity Search| DB
```

### Data Flow

1. **Document Upload**:

   - PDF â†’ PyMuPDF â†’ Text per page + Images (JPG)
   - Text â†’ OpenAI Embeddings (3072-d) â†’ pgvector
   - Images â†’ `/media/` folder

2. **Query Processing**:

   - User question â†’ Route decision (Docs/Web/Hybrid)
   - Vector search (cosine similarity) â†’ Top K pages
   - If visual query (logo, chart, etc.) â†’ Include images
   - GPT-4o processes text + images â†’ Grounded answer
   - Stream response with citations

3. **Multimodal Support**:
   - Detects visual queries: "logo", "grÃ¡fico", "imagem", etc.
   - Encodes images as base64 â†’ GPT-4o Vision
   - Renders images in chat using ReactMarkdown

---

## Quick Start

### Prerequisites

- Docker and Docker Compose
- OpenAI API key

### Setup

1. **Clone and configure**:

```bash
git clone <repo-url>
cd ai_rag_agent
cp .env.example .env
```

2. **Edit `.env`**:

```env
OPENAI_API_KEY=sk-your-key-here
DATABASE_URL=postgresql+asyncpg://user:password@db:5432/app
```

3. **Start services**:

```bash
docker compose up -d --build
```

4. **Access**:
   - Frontend: http://localhost:5173
   - Backend API: http://localhost:8080
   - API Docs: http://localhost:8080/docs

---

## Repository Structure

```
ai_rag_agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py            # Settings
â”‚   â”‚   â”œâ”€â”€ routes/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py          # SSE streaming chat
â”‚   â”‚   â”‚   â””â”€â”€ documents.py     # PDF upload
â”‚   â”‚   â”œâ”€â”€ services/            # Core business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py     # PDF â†’ DB + images
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # RAG orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ ranking.py       # Vector search
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # OpenAI client
â”‚   â”‚   â”‚   â””â”€â”€ web_search.py    # Web search
â”‚   â”‚   â”œâ”€â”€ prompts.py           # LLM prompts
â”‚   â”‚   â””â”€â”€ middleware.py        # Request logging
â”‚   â”œâ”€â”€ migrations/              # Alembic DB migrations
â”‚   â”œâ”€â”€ tests/                   # pytest tests
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx              # Main app
â”‚   â”‚   â”œâ”€â”€ api.ts               # API client
â”‚   â”‚   â””â”€â”€ components/          # React components
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## Environment Variables

Create `.env` from `.env.example`:

```env
# Required
OPENAI_API_KEY=sk-your-key-here
DATABASE_URL=postgresql+asyncpg://user:password@db:5432/app

# Optional
WEB_SEARCH_PROVIDER=tavily  # or brave, serper
WEB_SEARCH_API_KEY=your-search-api-key
LOG_LEVEL=INFO
MEDIA_ROOT=./media
```

---

## API Endpoints

### Documents

**POST /api/documents**

- Upload PDF files (multipart/form-data)
- Extracts text, images, generates embeddings
- Returns: `{ id, title, page_count }[]`

**GET /api/documents**

- List all uploaded documents
- Returns: `{ id, title, page_count }[]`

**DELETE /api/documents/{id}**

- Delete a document and its pages
- Returns: `{ success: true }`

### Chat

**POST /api/chat**

- Server-Sent Events (SSE) stream
- Request body:

```json
{
  "messages": [{ "role": "user", "content": "What is the logo?" }],
  "document_ids": ["uuid-here"],
  "force_web": false
}
```

- Response stream:
  - Tokens: `data: <token>\n\n`
  - Final envelope: `data: { ... }\n\nevent: end\n\n`

---

## Database Schema

### documents

```sql
CREATE TABLE documents (
  id UUID PRIMARY KEY,
  title TEXT,
  page_count INT,
  created_at TIMESTAMPTZ
);
```

### document_pages

```sql
CREATE TABLE document_pages (
  id UUID PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  page_number INT,
  content TEXT,
  embedding vector(3072),  -- OpenAI text-embedding-3-large
  created_at TIMESTAMPTZ
);
```

### document_page_images

```sql
CREATE TABLE document_page_images (
  id UUID PRIMARY KEY,
  document_page_id UUID REFERENCES document_pages(id) ON DELETE CASCADE,
  position INT,
  file_url TEXT,  -- /media/<uuid>.jpg
  dimensions JSONB  -- {"width": 1024, "height": 768}
);
```

---

## RAG Pipeline Details

### 1. Routing Decision

```python
# Auto mode: LLM decides based on query
if "investimento" in query or "preÃ§o" in query:
    use_docs = True
elif "notÃ­cia" in query or "hoje" in query:
    use_web = True
```

### 2. Vector Search

```sql
SELECT *, (embedding <=> query_embedding) AS distance
FROM document_pages
WHERE document_id = ANY($1)
ORDER BY distance ASC
LIMIT 15;
```

### 3. Semantic Reranking

- Deduplicates pages
- Sorts by `similarity DESC, page_number ASC`
- Batches of 3 pages, up to 15 total

### 4. Multimodal Synthesis

```python
# Detect visual queries
visual_keywords = ['logo', 'grÃ¡fico', 'imagem', 'foto']
if any(k in query.lower() for k in visual_keywords):
    # Encode images as base64 â†’ GPT-4o Vision
    images_b64 = [encode_image(img) for img in page_images]

# Build multimodal message
messages = [{
    "role": "user",
    "content": [
        {"type": "text", "text": query},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img}"}}
        for img in images_b64
    ]
}]

# GPT-4o Vision processes text + images
answer = await llm.chat("gpt-4o", messages)
```

---

## Frontend Features

### Chat Interface

- **Message Types**:
  - User messages: Blue gradient bubble
  - Assistant messages: White with markdown rendering
  - Citations: Blue badges `[1]` `[2]`
  - Images: Inline markdown images

### Mode Selection

- **Docs**: Search only uploaded PDFs
- **Web**: Search only the web
- **Auto**: LLM decides based on query

### Sources Panel

Shows grounded sources:

- Document pages with similarity scores
- Web search results with URLs
- Images from relevant pages

---

## Running Locally (Development)

### Backend

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # or .\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r backend/requirements.txt

# Run migrations
alembic -c backend/alembic.ini upgrade head

# Start server
uvicorn app.main:app --reload --port 8080 --app-dir backend
```

### Frontend

```bash
cd frontend
npm install
npm run dev  # http://localhost:5173
```

---

## Testing

### Unit Tests (pytest)

```bash
pytest backend/tests/
```

### RAG Evaluation (DeepEval)

```bash
# Set environment
export OPENAI_API_KEY=sk-...
export EVAL_DOCUMENT_ID=<uuid-from-upload>

# Run evaluation
deepeval test run backend/evaluation/test_evaluate_rag.py
```

---

## Troubleshooting

### Images not appearing

- Check `MEDIA_ROOT` is correctly mounted
- Verify images are saved: `ls backend/media/`
- Check browser console for 404 errors

### Poor search results

- Ensure embeddings were generated (check `document_pages.embedding`)
- Try increasing `RETRIEVAL_TOP_K` in config
- Use more specific queries

### "No API key" errors

- Verify `.env` has `OPENAI_API_KEY`
- Restart Docker containers after changing `.env`

---

## Production Checklist

- [ ] Set strong `DATABASE_URL` password
- [ ] Use production-grade PostgreSQL (not Docker for prod)
- [ ] Configure CORS properly in `backend/app/main.py`
- [ ] Set up HTTPS/TLS for frontend and backend
- [ ] Enable rate limiting and authentication
- [ ] Monitor costs (OpenAI API usage)
- [ ] Set up logging aggregation (Datadog, Sentry, etc.)
- [ ] Configure backup strategy for PostgreSQL
- [ ] Review and audit PyMuPDF licensing (AGPL)

---

## Tech Stack

**Backend**:

- FastAPI (async Python web framework)
- PostgreSQL 15+ with pgvector
- SQLAlchemy 2.0 (async ORM)
- PyMuPDF (PDF processing)
- Pillow (image processing)
- OpenAI Python SDK
- structlog (structured logging)

**Frontend**:

- React 18
- TypeScript
- Vite (build tool)
- TailwindCSS (styling)
- Framer Motion (animations)
- react-markdown (markdown rendering)
- Lucide React (icons)

**Infrastructure**:

- Docker + Docker Compose
- Alembic (database migrations)

---

## License

This project is an educational MVP. Dependencies have their own licenses:

- PyMuPDF: AGPL (commercial license available)
- OpenAI API: Usage subject to OpenAI terms

---

## Contributing

This is a study project. For suggestions or issues, please open a GitHub issue or contact the authors.

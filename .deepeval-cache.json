{"test_cases_lookup_map": {"{\"actual_output\": \"O investimento inicial dispon\\u00edvel para o neg\\u00f3cio \\u00e9 de R$ 15.000.\", \"context\": null, \"expected_output\": \"O capital inicial dispon\\u00edvel \\u00e9 de R$ 15.000.\", \"hyperparameters\": null, \"input\": \"Qual \\u00e9 o investimento inicial dispon\\u00edvel para o neg\\u00f3cio?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the response directly addresses the question without any irrelevant information. Great job on staying focused and relevant!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the actual output is perfectly aligned with the retrieval context. Great job on maintaining accuracy and consistency! Keep it up!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"A margem de lucro desejada \\u00e9 de 30% sobre o pre\\u00e7o de venda.\", \"context\": null, \"expected_output\": \"A margem de lucro desejada \\u00e9 de 30% sobre o pre\\u00e7o de venda.\", \"hyperparameters\": null, \"input\": \"Qual \\u00e9 a margem de lucro desejada sobre o pre\\u00e7o de venda?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the output is perfectly relevant to the input, providing a clear and focused response with no irrelevant information. Well done!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, indicating that the actual output aligns perfectly with the retrieval context. Keep up the great work maintaining such fidelity!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"Para atingir o ponto de equil\\u00edbrio, a padaria precisaria vender aproximadamente R$ 5.428,57 por m\\u00eas, o que equivale a cerca de 362 produtos a R$ 15,00 cada.\", \"context\": null, \"expected_output\": \"Para atingir o ponto de equil\\u00edbrio, a padaria precisa vender aproximadamente 362 produtos por m\\u00eas, o que corresponde a uma receita de cerca de R$ 5.428,57.\", \"hyperparameters\": null, \"input\": \"Quanto \\u00e9 preciso vender por m\\u00eas para atingir o ponto de equil\\u00edbrio?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the response is perfectly relevant and directly addresses the question asked without any irrelevant statements. Keep up the great work!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, indicating a perfect alignment between the actual output and the retrieval context. Fantastic job! Keep up the excellent work!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"O custo estimado para equipamentos essenciais de uma mini padaria, incluindo um forno, pode variar entre R$ 10.000 e R$ 15.000 [3].\", \"context\": null, \"expected_output\": \"O pre\\u00e7o estimado para um forno de convec\\u00e7\\u00e3o ou turbo varia de R$ 3.000 a R$ 8.000.\", \"hyperparameters\": null, \"input\": \"Qual o custo estimado para um forno de convec\\u00e7\\u00e3o?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the output is entirely relevant and accurately addresses the question about the estimated cost of a convection oven. Great job on providing a focused and pertinent response!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, which means the actual output perfectly aligns with the retrieval context. Great job maintaining consistency! Keep up the excellent work!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"Sim, \\u00e9 mencionada uma segunda rodada de investimento em 3 meses, mas o valor espec\\u00edfico n\\u00e3o \\u00e9 informado.\", \"context\": null, \"expected_output\": \"Sim, uma rodada de investimento futura de R$ 10.000 em 3 meses \\u00e9 mencionada como uma possibilidade para expandir o neg\\u00f3cio.\", \"hyperparameters\": null, \"input\": \"Uma rodada de investimento futura \\u00e9 mencionada? Qual o valor?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the response is perfectly relevant with no irrelevant statements, which directly answers the question about a future investment round and its value. Keep up the great work!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the actual output perfectly aligns with the retrieval context, showcasing impeccable accuracy and consistency. Keep up the excellent work!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"Os custos fixos mensais totais s\\u00e3o R$ 3.800 [1].\", \"context\": null, \"expected_output\": \"O total de custos fixos mensais \\u00e9 de R$ 3.800, sendo R$ 800 de aluguel e R$ 3.000 de sal\\u00e1rios para duas pessoas.\", \"hyperparameters\": null, \"input\": \"Quais s\\u00e3o os custos fixos mensais totais?\", \"retrieval_context\": [\"\", \"\", \"\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the response is perfectly relevant, directly addressing the question without any irrelevant information. Fantastic job!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}, {"metric_metadata": {"metric": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the actual output is perfectly aligned with the retrieval context. Fantastic job maintaining accuracy and faithfulness!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}}}